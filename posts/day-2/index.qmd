---
title: "Day 2: Time Series, Stationarity, and ARIMA Models"
author: "Robert W. Walker"
date: "07/22/2025"
categories: [time series, code, analysis]
image: "image1.png"
---

## Slides

- [A reveal presentation](https://robertwwalker.github.io/Essex-slides/ESSSSDA252W-Day2/)

## Simulating ARIMA processes

We want to simulate data under an ARIMA `(p, d, q)` model.  `arima.sim` wants inputs as a list where the expected length of the `ar` and `ma` vectors that will hold the actual values of the `ar` and `ma` parameters.  Here, I ask for a series that is I(1) with a first-order ar=0.1 and a first-order ma=-0.5.  Let me start by generating it and plotting the time series.

```{r}
library(fpp3)
n <- 100
my.data <- data.frame(
  x=arima.sim(n = n, 
              model=list(order = c(1, 1, 1), ar=c(0.7), ma=c(-0.5)), n.start=20), 
  dtime = seq(1,n+1))
library(magrittr)
my.data %<>% as_tsibble(index=dtime) 
my.data %>% autoplot() + labs(title="A (1, 1, 1) Series", x="Time")
```

Now I want to display the ACF and PACF in levels.

```{r}
library(patchwork)
{my.data %>% ACF(x, lag_max=20) %>% 
    autoplot() } + 
  {my.data %>% PACF(x, lag_max=20) %>% 
      autoplot() }
```

Finally, let me display the ACF and PACF with differenced data.

```{r}
{my.data %>% ACF(diff(x), lag_max=20) %>% 
    autoplot() } + 
  {my.data %>% PACF(diff(x), lag_max=20) %>% 
      autoplot() }
```


## Nonsense Regressions of I(1) Series


```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## An Example of Time Series Troubles

Let me do this with a relatively simple regression.  Two variables: 

$$ y = \alpha + \beta x + \epsilon $$

Both are generated randomly.  Here's a basic plot.

```{r}
y <- cumsum(rnorm(100))
x <- cumsum(rnorm(100))
plot(x=seq(1:100), y=y, type="l", col="red", ylim=c(-15,15))
lines(x=seq(1:100), y=x, col="blue")
```

Each time series contains 100 observations.  Because both x and y are random, the slopes should be 0, 95% of the time with 95% confidence because there is no underlying relationship.  In practice, let's look at the distribution of p-values for the probability of no relationship.

```{r}
SR <- function(n) {
  Results <- NULL
  for(i in 1:n) {
y <- cumsum(rnorm(100))
x <- cumsum(rnorm(100))
Result <- summary(lm(y~x))$coefficients[2,4]
Results <- append(Result,Results)
  }
  Results
}
```

I replicate the process of random x and random y 1000 times and show the p-values below.  Because they are random, approximately 95% should be greater than 0.05.

```{r}
Res1 <- SR(1000)
plot(density(Res1), main="Distribution of p-values from Trending x")
```

In practice,

```{r}
table(Res1 > 0.05)
```

The above table should show about 950 TRUE and 50 FALSE but because each is trended and they share variation from trend, the actual frequency of rejecting the claim of no relationship is far more common than 5%.


## ARIMA Models with Government Popularity

```{r, message=FALSE, warning=FALSE}
library(fpp3)
library(haven)
br7983 <- read_dta(url("https://github.com/robertwwalker/Essex-Data/raw/main/br7983.dta")) %>% 
  mutate(month = as.character(month)) %>% 
  mutate(month = paste0("19",month, sep="")) %>% 
  mutate(date = yearmonth(month, format="%Y%m"))
br7983 <- br7983 %>% as_tsibble(index=date) 
br7983 %>% autoplot(govpopl) + hrbrthemes::theme_ipsum() + labs(y="logged Government Popularity")
```

## Time Series Features

```{r}
br7983 %>% gg_tsdisplay(govpopl, plot_type = "partial")
```

```
library(haven)
# To install TSA, it works in three steps.
# Link to package
# https://cran.r-project.org/web/packages/TSA/index.html
# The archive for the package is:
# https://cran.r-project.org/src/contrib/Archive/TSA/
# I grabbed the most recent one.
# Then I used the RStudio: Tools > Install Packages > From a local archive
# And installed it.
# It had dependency chains to fix.
# Those can be fixed with
# install.packages(c("leaps", "locfit", "mgcv"))
```

```{r, message=FALSE, warning=FALSE}
library(TSA)
# Replicating the abrupt permanent in April
arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xreg=br7983$flandd)
```

```{r}
# Replicating the abrupt permanent in May
arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xreg=br7983$flanddlag1)
```

```{r}
# Replicating the gradual permanent April
arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flandd, transfer = list(c(1,0)))
```

```{r}
# Replicating the gradual permanent May
# Does not work; degrees of freedom?
# arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flanddlag1, transfer = list(c(1,0)))
# Falklands - gradual temporary (pulse decay) effect - May 1982
# Does not work; degrees of freedom?
# arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flanddlag1, transfer = list(c(1,1)))
# These are fairly demanding [of the data] models.
arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flandd, transfer = list(c(1,0)))
```

### ARIMA

Stata covers this [in the following link](https://www.stata.com/features/time-series/ts-arima.pdf).

```
wpi1 <- read_stata(url("http://www.stata-press.com/data/r12/wpi1.dta"))
wpi1$date <- yearquarter(wpi1$t, fiscal_start = 1)-40
```

```{r}
load(url("https://github.com/robertwwalker/Essex-Data/raw/main/wpi1.RData"))
wpi1 %>% as_tsibble(index=date) %>% gg_tsdisplay(ln_wpi, plot_type = "partial") + labs(title="Log WPI")
```

### Stata

```
arima wpi, arima(1,1,1)
```

### R

```{r}
wpi1 %>% as_tsibble(index=date) %>% 
  model(arima = ARIMA(wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,0))) %>% 
  report()
```

The help for ARIMA explains the alternative parameterization.

```{r}
# Using stats::arima
arima(diff(wpi1$wpi), order=c(1,0,1), include.mean = TRUE)
```

## Seasonal

```
arima D.ln_wpi, ar(1) ma(1 4)
```

```{r}
wpi1 %>% as_tsibble(index=date) %>% 
  model(arima = ARIMA(ln_wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,1))) %>% 
  report()
```

There are also bits about seasonal arima -- `sarima` -- and arimax but Stata is fundamentally limited here.

```{r}
wpi1 %>% as_tsibble(index=date) %>% 
  model(arima = ARIMA(ln_wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,1))) %>% 
  gg_tsresiduals()
```

That works.

## Spurious Regressions

```
# Simulation considers replicating cross-sections
x <- rnorm(100)
y <- rnorm(100)
summary(lm(y ~ x))
beta <- matrix(data=NA, nrow=100, ncol=4)
beta[1,] <- summary(lm(y ~ x))$coefficients[2,]
my.df <- data.frame(y=y, x=x)
for (i in 2:100) {
  x2 <- rep(x, i)
  y2 <- rep(y, i)
  my.df2 <- data.frame(x=x2, y=y2)
  beta[i,] <- summary(lm(y ~ x, data=my.df2))$coefficients[2,]
  }
plot(x=seq(1,100), y=beta[,4], main="Replicating Cross-Sections", xlab="Number of Repetitions", ylab="p-value")
abline(h=0.05, lty=2)

# Simulation considers the spurious regressions problem
y.ts <- arima.sim(list(order = c(1,1,0), ar = 0.007), n = 200)
x.ts <- arima.sim(list(order = c(1,1,0), ar = 0.007), n = 200)
par(mfrow=c(2,1))
ts.plot(y.ts)
ts.plot(x.ts)
summary(lm(y.ts ~ x.ts))
for (i in 1:1000) {
  y.ts.sim <- arima.sim(list(order = c(1,1,0), ar = 0.007), n = 200)
  x.ts.sim <- arima.sim(list(order = c(1,1,0), ar = -0.001), n = 200)
  beta.ts[i] <- summary(lm(y.ts.sim ~ x.ts.sim))$coefficients[2,4]
  }
plot(density(beta.ts), main="Spurious Regressions")
table((beta.ts<0.05))
```

Yule, in 1926, shows the consequences of regressing nonstationary series on one another.  To replicate his result via simulation, let's perform one.  First, to generate two nonstationary series.  Then regress them on each other and keep the p-value for the slope attached to $y_2$.

```{r}
library(tidyverse)
Spurious <- function(junk) {
y1 <- arima.sim(n=200, list(order=c(0,1,0)))
y2 <- arima.sim(n=200, list(order=c(0,1,0)))
return(summary(lm(y1~y2))$coefficients[2,4])
}
Spurious.Result <- data.frame(Res=sapply(1:1000, function(x) {Spurious(x)}))
```

Finally, let's plot the p-values.

```{r}
Spurious.Result %>% ggplot(., aes(x=Res)) + geom_histogram()
```

